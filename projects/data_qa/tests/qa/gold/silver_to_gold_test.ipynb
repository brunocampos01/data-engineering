{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T13:22:07.487016Z",
     "start_time": "2024-11-02T13:21:54.698293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from IPython.display import (\n",
    "    display,\n",
    "    HTML,\n",
    ")\n",
    "\n",
    "from library.qa.silver_to_gold_test_data import SilverToGoldTestData\n",
    "from library.qa.utils import (\n",
    "    get_file_from_widget,\n",
    "    get_list_from_widget,\n",
    "    get_dict_from_widget,\n",
    ")\n"
   ],
   "id": "5c07d3a8fe1ba31b",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dbruntime'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 9\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mIPython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdisplay\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m      5\u001B[0m     display,\n\u001B[1;32m      6\u001B[0m     HTML,\n\u001B[1;32m      7\u001B[0m )\n\u001B[0;32m----> 9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlibrary\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mqa\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msilver_to_gold_test_data\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SilverToGoldTestData\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlibrary\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mqa\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     11\u001B[0m     get_file_from_widget,\n\u001B[1;32m     12\u001B[0m     get_list_from_widget,\n\u001B[1;32m     13\u001B[0m     get_dict_from_widget,\n\u001B[1;32m     14\u001B[0m )\n",
      "File \u001B[0;32m~/projects/avenue_code/csl/DataTeam-Databricks/library/qa/silver_to_gold_test_data.py:56\u001B[0m\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlibrary\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mqa\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtemplate_data_tests\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TemplateDataTest\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlibrary\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mqa\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgreat_expectations_helper\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GreatExpectationsHelper\n\u001B[0;32m---> 56\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlibrary\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mqa\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcustom_data_tests\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgold_qa\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GoldQA \u001B[38;5;28;01mas\u001B[39;00m gold_test\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlibrary\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mqa\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcustom_data_tests\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon_tests\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m CommonQA \u001B[38;5;28;01mas\u001B[39;00m custom_qa\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlibrary\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mqa\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtimestamp_helper\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TimestampHelper\n",
      "File \u001B[0;32m~/projects/avenue_code/csl/DataTeam-Databricks/library/qa/custom_data_tests/gold_qa.py:23\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m col, regexp_replace\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtypes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TimestampType\n\u001B[0;32m---> 23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlibrary\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mqa\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcustom_data_tests\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcommon_tests\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m CommonQA \u001B[38;5;28;01mas\u001B[39;00m custom_qa\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlibrary\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mqa\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LogTag\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlibrary\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgreat_expectations\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m add_custom_result_to_validation\n",
      "File \u001B[0;32m~/projects/avenue_code/csl/DataTeam-Databricks/library/qa/custom_data_tests/common_tests.py:25\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlibrary\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdatacleaner\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdefaults\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Defaults \u001B[38;5;28;01mas\u001B[39;00m col_silver\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlibrary\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgreat_expectations\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m add_custom_result_to_validation\n\u001B[0;32m---> 25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlibrary\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mqa\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LogTag\n\u001B[1;32m     26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlibrary\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mqa\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     27\u001B[0m     get_common_cols,\n\u001B[1;32m     28\u001B[0m     find_df_diff,\n\u001B[1;32m     29\u001B[0m     get_cols_with_data_precision,\n\u001B[1;32m     30\u001B[0m )\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mCommonQA\u001B[39;00m:\n",
      "File \u001B[0;32m~/projects/avenue_code/csl/DataTeam-Databricks/library/qa/utils.py:36\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpprint\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pprint\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01menum\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Enum\n\u001B[0;32m---> 36\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdbruntime\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdbutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DBUtils\n\u001B[1;32m     38\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     39\u001B[0m     DataFrame,\n\u001B[1;32m     40\u001B[0m     SparkSession,\n\u001B[1;32m     41\u001B[0m     Row,\n\u001B[1;32m     42\u001B[0m )\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpyspark\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msql\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     44\u001B[0m     col, \n\u001B[1;32m     45\u001B[0m     lit,\n\u001B[1;32m     46\u001B[0m )\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'dbruntime'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-02T13:22:11.448525Z",
     "start_time": "2024-11-02T13:22:11.442409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "spark.table('dev_silver.hsbc_sftp.payment_status').display()"
   ],
   "id": "e626877dd8e25cbc",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mspark\u001B[49m\u001B[38;5;241m.\u001B[39mtable(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdev_silver.hsbc_sftp.payment_status\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mdisplay()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'spark' is not defined"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# DBTITLE 1,Debug: Initial Paramaters\n",
    "# ---\n",
    "# required parameters\n",
    "dbutils.widgets.text(\"sql_database\", \"\") # onpremise, azsql\n",
    "dbutils.widgets.text(\"catalog_db_name\", \"\") # XPTOdw\n",
    "dbutils.widgets.text(\"schema_db_name\", \"\") # dw\n",
    "dbutils.widgets.text(\"table_db_name\", \"\") # fact_vessel_procurement_cumul_snapshot\n",
    "dbutils.widgets.text(\"schema_gold_name\", \"\") # dw_procurement, dw_commercial\n",
    "dbutils.widgets.text(\"table_gold_name\", \"\") # fact_ship_procurement_cumul_snapshot\n",
    "dbutils.widgets.text(\"table_type\", \"fact\") # fact or dim\n",
    "dbutils.widgets.text(\"query_path\", \"\")  # based on Sql Server => example: resources/sql/bi_procurement/facts/fact_ship_procurement_cumul_snapshot.sql\n",
    "dbutils.widgets.text(\"datatypes_definition_file\", '') # based on Sql Server => example: resources/schemas/bi_procurement/facts/fact_ship_procurement_cumul_snapshot.json\n",
    "dbutils.widgets.text(\"dict_rename_cols\", '''{\n",
    "    \"vessel\": \"ship\",\n",
    "    \"division\": \"region\",\n",
    "    \"interval_lenght_uom\": \"interval_length_uom\",\n",
    "    \"interval_lenght_value\": \"interval_length_value\",\n",
    "    \"pos_type\": \"type\",\n",
    "    \"pos_status\": \"status\"\n",
    "}''')\n",
    "\n",
    "# ---\n",
    "# optional parameters\n",
    "dbutils.widgets.text(\"col_prefix\", \"\") # the existing prefix in PK col, if not have it, remove parameter => Example: fvpcs\n",
    "# dbutils.widgets.text(\"list_skip_cols\", \"\") # skip all tests\n",
    "# dbutils.widgets.text(\"list_skip_cols_check_content\", \"delete_or_inactive_date\") # skip only the expect_same_content_rows test\n",
    "# dbutils.widgets.text(\"list_skip_cols_not_null\", \"completed_date_sk, resch_date_sk, resch_reason_sk, started_date_sk\") # skip only the expect_column_values_to_not_be_null test\n",
    "# dbutils.widgets.text(\"list_skip_cols_fk_constraint\", \"expected_delivery_date_sk, invoice_date_sk, order_date_sk, received_date_sk, requested_delivery_date_sk\") # skip only the expect_col_fk test"
   ],
   "id": "4aee7fba48e7fae",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# MAGIC %md\n",
    "# MAGIC # Silver to Gold Test Data\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# DBTITLE 1,Auto reload and rehasx\n",
    "# MAGIC %load_ext autoreload\n",
    "# MAGIC %autoreload 2\n",
    "# MAGIC %rehashx # clear cache\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Imports\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# DBTITLE 1,Imports\n",
    "import json\n",
    "import os\n",
    "\n",
    "from IPython.display import (\n",
    "    display,\n",
    "    HTML,\n",
    ")\n",
    "\n",
    "from library.qa.silver_to_gold_test_data import SilverToGoldTestData\n",
    "from library.qa.utils import (\n",
    "    get_file_from_widget,\n",
    "    get_list_from_widget,\n",
    "    get_dict_from_widget,\n",
    ")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Prepare Parameters\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# DBTITLE 1,Remove old parameters\n",
    "dbutils.widgets.removeAll()\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# DBTITLE 1,Debug: Initial Paramaters\n",
    "# ---\n",
    "# required parameters\n",
    "dbutils.widgets.text(\"sql_database\", \"\") # onpremise, azsql\n",
    "dbutils.widgets.text(\"catalog_db_name\", \"\") # XPTOdw\n",
    "dbutils.widgets.text(\"schema_db_name\", \"\") # dw\n",
    "dbutils.widgets.text(\"table_db_name\", \"\") # fact_vessel_procurement_cumul_snapshot\n",
    "dbutils.widgets.text(\"schema_gold_name\", \"\") # dw_procurement, dw_commercial\n",
    "dbutils.widgets.text(\"table_gold_name\", \"\") # fact_ship_procurement_cumul_snapshot\n",
    "dbutils.widgets.text(\"table_type\", \"fact\") # fact or dim\n",
    "dbutils.widgets.text(\"query_path\", \"\")  # based on Sql Server => example: resources/sql/bi_procurement/facts/fact_ship_procurement_cumul_snapshot.sql\n",
    "dbutils.widgets.text(\"datatypes_definition_file\", '') # based on Sql Server => example: resources/schemas/bi_procurement/facts/fact_ship_procurement_cumul_snapshot.json\n",
    "dbutils.widgets.text(\"dict_rename_cols\", '''{\n",
    "    \"vessel\": \"ship\",\n",
    "    \"division\": \"region\",\n",
    "    \"interval_lenght_uom\": \"interval_length_uom\",\n",
    "    \"interval_lenght_value\": \"interval_length_value\",\n",
    "    \"pos_type\": \"type\",\n",
    "    \"pos_status\": \"status\"\n",
    "}''')\n",
    "\n",
    "# ---\n",
    "# optional parameters\n",
    "dbutils.widgets.text(\"col_prefix\", \"\") # the existing prefix in PK col, if not have it, remove parameter => Example: fvpcs\n",
    "# dbutils.widgets.text(\"list_skip_cols\", \"\") # skip all tests\n",
    "# dbutils.widgets.text(\"list_skip_cols_check_content\", \"delete_or_inactive_date\") # skip only the expect_same_content_rows test\n",
    "# dbutils.widgets.text(\"list_skip_cols_not_null\", \"completed_date_sk, resch_date_sk, resch_reason_sk, started_date_sk\") # skip only the expect_column_values_to_not_be_null test\n",
    "# dbutils.widgets.text(\"list_skip_cols_fk_constraint\", \"expected_delivery_date_sk, invoice_date_sk, order_date_sk, received_date_sk, requested_delivery_date_sk\") # skip only the expect_col_fk test\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# DBTITLE 1,Parameters\n",
    "sql_database = dbutils.widgets.get(\"sql_database\")\n",
    "catalog_db_name = dbutils.widgets.get(\"catalog_db_name\")\n",
    "schema_db_name = dbutils.widgets.get(\"schema_db_name\")\n",
    "table_db_name = dbutils.widgets.get(\"table_db_name\")\n",
    "schema_gold_name = dbutils.widgets.get(\"schema_gold_name\")\n",
    "table_gold_name = dbutils.widgets.get(\"table_gold_name\")\n",
    "table_type = dbutils.widgets.get(\"table_type\")\n",
    "list_col_prefix = get_list_from_widget(dbutils, \"col_prefix\")\n",
    "query = get_file_from_widget(dbutils, \"query_path\")\n",
    "dict_schema_expected = get_file_from_widget(dbutils, \"datatypes_definition_file\", is_json=True)\n",
    "list_skip_cols = get_list_from_widget(dbutils, \"list_skip_cols\")\n",
    "list_skip_cols_check_content = get_list_from_widget(dbutils, \"list_skip_cols_check_content\")\n",
    "dict_rename_cols = dbutils.widgets.get(\"dict_rename_cols\")\n",
    "list_skip_cols_not_null = get_list_from_widget(dbutils, \"list_skip_cols_not_null\")\n",
    "list_skip_cols_fk_constraint = get_list_from_widget(dbutils, \"list_skip_cols_fk_constraint\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "data_tester = SilverToGoldTestData(\n",
    "    spark=spark,\n",
    "    sql_database=sql_database,\n",
    "    catalog_db_name=catalog_db_name,\n",
    "    schema_db_name=schema_db_name,\n",
    "    table_db_name=table_db_name,\n",
    "    schema_gold_name=schema_gold_name,\n",
    "    table_gold_name=table_gold_name,\n",
    "    table_type=table_type,\n",
    "    query=query,\n",
    "    dict_schema_expected=dict_schema_expected,\n",
    "    list_col_prefix=list_col_prefix,\n",
    "    list_skip_cols=list_skip_cols,\n",
    "    list_skip_cols_check_content=list_skip_cols_check_content,\n",
    "    dict_rename_cols=json.loads(dict_rename_cols),\n",
    "    list_skip_cols_not_null=list_skip_cols_not_null,\n",
    "    list_skip_cols_fk_constraint=list_skip_cols_fk_constraint,\n",
    ")\n",
    "data_tester.log_execution_parameters()\n",
    "data_tester.validate_parameters()\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Load Data\n",
    "# MAGIC If it is necessary to debug and see what was received from the sources, use the `df_sql_server` or `df_uc`.\n",
    "# MAGIC\n",
    "# MAGIC |   SQL Server  | Unity Catalog |\n",
    "# MAGIC |---------------|---------------|\n",
    "# MAGIC | df_sql_server | df_uc         |\n",
    "# MAGIC | Expected      | Observed      |\n",
    "# MAGIC | Source        | Target        |\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "(\n",
    "    df_uc,\n",
    "    df_sql_server,\n",
    ") = data_tester.get_and_prepare_data()\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Execute Data Test\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "validation_results = data_tester.execute_data_tests(\n",
    "    df_expected=df_sql_server,\n",
    "    df_expected_name='sql_database',\n",
    "    df_observed=df_uc,\n",
    "    df_observed_name='uc',\n",
    ")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "html_result_gx = data_tester.generate_results_html(validation_results)\n",
    "display(HTML(html_result_gx))\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ### Not Null Constraint\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "print('uc info_schema:')\n",
    "data_tester._get_uc_info_schema().display()\n",
    "\n",
    "print('sql server info_schema:')\n",
    "data_tester._get_sql_server_info_schema().display()\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Elapsed time to get the same number of records returned\n",
    "# MAGIC - Sql Server\n",
    "# MAGIC ```sql\n",
    "# MAGIC DECLARE @StartTime DATETIME;\n",
    "# MAGIC DECLARE @EndTime DATETIME;\n",
    "# MAGIC DECLARE @ElapsedTime INT;\n",
    "# MAGIC\n",
    "# MAGIC SET @StartTime = GETDATE();\n",
    "# MAGIC SELECT * FROM XPTOdw.dw.<TABLE_NAME>;\n",
    "# MAGIC SET @EndTime = GETDATE();\n",
    "# MAGIC\n",
    "# MAGIC SET @ElapsedTime = DATEDIFF(MILLISECOND, @StartTime, @EndTime);\n",
    "# MAGIC\n",
    "# MAGIC SELECT\n",
    "# MAGIC \t@StartTime AS StartTime,\n",
    "# MAGIC \t@EndTime AS EndTime,\n",
    "# MAGIC \t@ElapsedTime AS 'ms';\n",
    "# MAGIC ```\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Data Analysis / Debug\n",
    "# MAGIC - Use these cells to analyze the dataframes, schemas, data_tests, diffs\n",
    "# MAGIC - Use only to debug! Avoid keep this cell related the debug uncommented because some functions consume a lot of time tu run.\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# DBTITLE 1,Debug: Data Analysis\n",
    "# from library.qa.utils import (\n",
    "#     find_df_diff,\n",
    "#     get_common_cols,\n",
    "#     initialize_and_prepare_delta,\n",
    "# )\n",
    "\n",
    "# list_cols = get_common_cols(df_sql_server, df_uc)\n",
    "# df_sql_server_business_cols = df_sql_server.select(*list_cols)\n",
    "# df_uc_business_cols = df_uc.select(*list_cols)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# DBTITLE 1,Debug: Check Diff between DFs\n",
    "# (\n",
    "#     df_diff_source_target,\n",
    "#     df_diff_target_source\n",
    "# ) = find_df_diff(df_source=df_sql_server_business_cols.select('cust_ratio'),\n",
    "#                  df_target=df_uc_business_cols.select('cust_ratio'))\n",
    "\n",
    "# list_cols_order_by = df_diff_source_target.columns\n",
    "\n",
    "# print(f'All df_diff: (df_sql_server_business_cols - df_uc_business_cols) rows:')\n",
    "# if len(list_cols_order_by) > 0:\n",
    "#     df_diff_source_target.orderBy(*list_cols_order_by).display()\n",
    "# else:\n",
    "#     df_diff_source_target.display()\n",
    "\n",
    "# print(f'All df_diff: (df_uc_business_cols - df_sql_server_business_cols) rows:')\n",
    "# if len(list_cols_order_by) > 0:\n",
    "#     df_diff_target_source.orderBy(*list_cols_order_by).display()\n",
    "# else:\n",
    "#     df_diff_target_source.display()\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Save Results at Azure Blob Storage\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "data_tester.save_report_tests_azure_storage(\n",
    "    html_result_gx=html_result_gx,\n",
    "    container_name=data_tester.container_adls_name,\n",
    "    step_layer=data_tester.step_layer,\n",
    "    schema_target_name=data_tester.schema_gold_name,\n",
    "    table_target_name=data_tester.table_gold_name,\n",
    ")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Results\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "report = data_tester.display_results(validation_results)\n",
    "dbutils.notebook.exit(report)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
